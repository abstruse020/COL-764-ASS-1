{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas- \n",
    "# while saving conpressed postintgs list make\n",
    "# whether to use ?|\\/ for tokenization\n",
    "# iterate over all elements in posting list and save them (will save lots of characters so should reduce writing time)\n",
    "# To save memory - save postings list in next line and while merging only fetch terms and if they match then only get their postings list\n",
    "\n",
    "#implemented\n",
    "# could use bisect insort to insert to list in sorted order (no need now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO-\n",
    "#merge multiple postings list into 1 (other file)\n",
    "\n",
    "\n",
    "# DONE- \n",
    "#dictionary list (posting lists) are not sorted currently(could do using bisect insort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"tipster-ap-frac/ap880212\",'r')\n",
    "# ap890520\n",
    "def getFileContents(fileName):\n",
    "    contents = []\n",
    "    with open(fileName,'r') as file:\n",
    "        contents = file.read()\n",
    "    contents = \"<start>\" + contents + \"</start>\"\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def generateTermDictPart(xmlContents,docnos,term_dict = {}, xmlTagsList = ['HEAD', 'TEXT']):\n",
    "    docs = xmlContents.find_all('DOC')\n",
    "    tokens = []\n",
    "    for doc in docs:\n",
    "        doc_id = doc.find_all('DOCNO')[0].get_text()\n",
    "        docnos.append(doc_id)\n",
    "        doc_id = len(docnos)\n",
    "        #print(doc_id)\n",
    "        for tag in xmlTagsList:\n",
    "            tag_all = doc.find_all(tag)\n",
    "            for t in tag_all:\n",
    "                for localToken in filter(None, re.split(\"[, \\-'\\\"\\n()\\[\\]\\\\{}:.;`]+\",t.get_text())):\n",
    "                    tokens.append([localToken,doc_id])\n",
    "                    #print(localToken, end=\" \");\n",
    "                    if localToken not in term_dict:\n",
    "                        term_dict[localToken] = [doc_id]\n",
    "                    elif term_dict[localToken][-1] != doc_id:\n",
    "                        term_dict[localToken].append(doc_id)\n",
    "    return term_dict,docnos\n",
    "    #save the term dict in file\n",
    "    #empty the term_dict -- no need will call new method for new file so term_dict will be empty\n",
    "    #return to continue execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "def saveTermDict(term_dict, fileName):\n",
    "    import datetime\n",
    "    a = datetime.datetime.now()\n",
    "    with open('temp/'+fileName, 'a') as file:\n",
    "        for key in sorted(term_dict):\n",
    "            file.write('%s %s\\n'%(key, sorted(term_dict[key])))\n",
    "            #print(type(term_dict[key]), sorted(term_dict[key]))\n",
    "    b = datetime.datetime.now()\n",
    "    print('save success time taken ='+ str(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "save success time taken =0:00:00.200484\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "got term_dict\n",
      "save success time taken =0:00:00.285210\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "term_dict = {}\n",
    "# save term dict for set number of files together in a file\n",
    "saveToFileAt = 10\n",
    "fileNameIndex = 1\n",
    "def makeTermDictFiles(collectionPath):\n",
    "    global fileNameIndex\n",
    "    i=1\n",
    "    docnos=[]\n",
    "    term_dict = {}\n",
    "    for fileName in glob.glob(os.path.join(collectionPath, \"*\")):\n",
    "        contents = getFileContents(fileName)\n",
    "        contents = BeautifulSoup(contents, 'xml')\n",
    "        term_dict,docnos = generateTermDictPart(contents,docnos,term_dict)\n",
    "        #print(len(docnos))\n",
    "        print(\"got term_dict\")\n",
    "        if (i)%saveToFileAt == 0:\n",
    "            saveTermDict(term_dict, \"TempTermDoc-\"+str(fileNameIndex))\n",
    "            fileNameIndex = fileNameIndex + 1\n",
    "            term_dict = {}\n",
    "        i = i+1\n",
    "        #remove the below if to get all the files\n",
    "        if i> 20:\n",
    "            print(term_dict)\n",
    "            break\n",
    "    #save if term_dict is not empty (not a multiple of saveToFileAt)\n",
    "    if bool(term_dict):\n",
    "        saveTermDict(term_dict,\"TempTermDoc-\"+str(fileNameIndex))\n",
    "        fileNameIndex = fileNameIndex + 1\n",
    "    #now merge the posting list to a single file\n",
    "makeTermDictFiles('tipster-ap-frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file should be alrea by opened\n",
    "def nextTerm(file):\n",
    "    term = ''\n",
    "    endFile = False\n",
    "    postingList = []\n",
    "    line = file.readline()\n",
    "    if not line:\n",
    "        return term, postingList, True\n",
    "    line = list(filter(None, re.split(\"[ ,\\[\\]]+\",line)))\n",
    "    term = line[0]\n",
    "    postingList = [int(x) for x in line[1:-1]]\n",
    "    return term, postingList, endFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it efficient (o(n)) currently(o(log n))\n",
    "def mergeLists(lists):\n",
    "    lists = [el for li in lists for el in li]\n",
    "    return sorted(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePList(term, Plist):\n",
    "    with open('PostingsListNoCompression', 'a') as file:\n",
    "        file.write('%s %s\\n'%(term, Plist))\n",
    "#         file.write('%s '%(term))\n",
    "#         lastTerm = Plist[-1]\n",
    "#         for item in Plist:\n",
    "#             if item != lastTerm:\n",
    "#                 file.write('%s,'%(item))\n",
    "#             else:\n",
    "#                 file.write('%s\\n'%(item))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time :0:00:13.230580\n"
     ]
    }
   ],
   "source": [
    "# could remove eofs and use terms = '' for breaking the loop\n",
    "import datetime\n",
    "FilesWithList = fileNameIndex - 1\n",
    "def mergePostingsLists():\n",
    "    terms = ['']*FilesWithList\n",
    "    postingsLists = [[]]*FilesWithList\n",
    "    files = [ open('temp/TempTermDoc-'+ str(i+1)) for i in range(FilesWithList)]\n",
    "    eofs = [False] * FilesWithList\n",
    "    #initial initialisation\n",
    "    for i in range(FilesWithList):\n",
    "        terms[i], postingsLists[i], eofs[i] = nextTerm(files[i])\n",
    "    a = datetime.datetime.now()\n",
    "    while True:\n",
    "        # find min in terms except '' (if eof is reached those terms are = ''(empty string))\n",
    "        minTerm = min([term for term in terms if term != ''])\n",
    "        minTermsIndex = []\n",
    "        for term, index in zip(terms, range(len(terms))):\n",
    "            if term == minTerm:\n",
    "                minTermsIndex.append(index)\n",
    "        #merge Postings Lists\n",
    "        #t1 = datetime.datetime.now()\n",
    "        minTermPList = mergeLists([postingsLists[i] for i in minTermsIndex])\n",
    "        #t2 = datetime.datetime.now()\n",
    "        #print('merger :',t2-t1)\n",
    "        #save Postings Lists (could be combined with above to save mem?)\n",
    "        savePList(minTerm, minTermPList)\n",
    "        #t3 = datetime.datetime.now()\n",
    "        #print('save :', t3 - t2)\n",
    "        #iterate to next terms\n",
    "        for index in minTermsIndex:\n",
    "            terms[index], postingsLists[index], eofs[index] = nextTerm(files[index])\n",
    "        #if all eofs reached end the loop continue the loop\n",
    "        if all(eofs):\n",
    "            break\n",
    "    for f in files:\n",
    "        f.close()\n",
    "    b = datetime.datetime.now()\n",
    "    print('time :'+ str(b - a))\n",
    "    #print(terms)\n",
    "    #print(postingsLists)\n",
    "        \n",
    "mergePostingsLists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gapEncoding(postingList):\n",
    "    for i in range(1,postingList):\n",
    "        postingList[i] = postingList[i] - postingList[i-1]\n",
    "    return postingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compresC1(postingList):\n",
    "    finalAns = ''\n",
    "    for item in postingList:\n",
    "        ans = ''\n",
    "        binItem = bin(item)\n",
    "        n = len(binItem)\n",
    "        print(binItem)\n",
    "        for i in range(n-1,1, -1):\n",
    "            ans = binItem[i] + ans\n",
    "            if ((i+1) % 7) == 0:\n",
    "                ans = '1' + ans\n",
    "        if (len(ans)%8) != 0:\n",
    "            tem = 8 - len(ans)%8 - 1\n",
    "            ans = \"0\"*(8 - (len(ans)%8)-1) + ans\n",
    "            print('this',ans)\n",
    "            ans = '1' + ans\n",
    "        ans = list(ans)\n",
    "        ans[-8] = '0'\n",
    "        print(ans)\n",
    "        finalAns = finalAns + \"\".join(ans)\n",
    "    return finalAns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b1\n",
      "this 0000001\n",
      "['0', '0', '0', '0', '0', '0', '0', '1']\n",
      "0b10\n",
      "this 0000010\n",
      "['0', '0', '0', '0', '0', '0', '1', '0']\n",
      "0b100\n",
      "this 0000100\n",
      "['0', '0', '0', '0', '0', '1', '0', '0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'000000010000001000000100'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compresC1([1,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ans = int(i/7)\n",
    "    if (i%7) !=0:\n",
    "        ans = ans+1\n",
    "    print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "4 1\n",
      "6 2\n"
     ]
    }
   ],
   "source": [
    "kuch = [2,4,6]\n",
    "for k, i in zip(kuch, range(len(kuch))):\n",
    "    print(k,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\n"
     ]
    }
   ],
   "source": [
    "print(min([term for term in ['','Hello','$'] if term != '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 4, 5, 6, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "ini_list = [[1, 2, 3],\n",
    "            [3, 6, 7],\n",
    "            [7, 5, 4]]\n",
    "ini_list = [ el for li in ini_list for el in li]\n",
    "print(sorted(ini_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(fileNameIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term = harsh\n",
      "[1, 3, 6]\n",
      "False\n",
      "term = other\n",
      "[4, 6, 99]\n",
      "False\n",
      "term = one\n",
      "[40]\n",
      "False\n",
      "term = \n",
      "[]\n",
      "True\n",
      "term = \n",
      "[]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#testing nextTerm\n",
    "f1 = open('test','r')\n",
    "eof = False\n",
    "i=5\n",
    "# while not eof:\n",
    "while i:\n",
    "    term , plist, eof = nextTerm(f1)\n",
    "    print('term = '+ str(term))\n",
    "#     print(type(term))\n",
    "    print(plist)\n",
    "    print(eof)\n",
    "    i = i-1\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\n",
      "o\\\n",
      "this\n",
      "is\n",
      "harsh\n"
     ]
    }
   ],
   "source": [
    "for i in filter(None, re.split(\"[, \\-'\\\"\\n()\\[\\]/{}:.;|`]+\",\"hell-o\\/ this| is harsh]}[{}]\")):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "print(len(glob.glob(os.path.join('tipster-ap-frac', \"*\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# docs = xmlcontents.find_all('DOC')\n",
    "# tokens = []\n",
    "# xmlTagsList = ['HEAD', 'TEXT']\n",
    "# term_dict = {}\n",
    "# for doc in docs:\n",
    "#     doc_id = doc.find_all('DOCNO')[0].get_text()\n",
    "#     print(doc_id)\n",
    "#     for tag in xmlTagsList:\n",
    "#         tag_all = doc.find_all(tag)\n",
    "#         for t in tag_all:\n",
    "# #             print('tag = '+ str(t))\n",
    "#             for localToken in filter(None, re.split(\"[, \\-'\\\"\\n():.;]+\",t.get_text())):\n",
    "#                 print(localToken, end=\" \");\n",
    "#                 if localToken not in term_dict:\n",
    "#                     term_dict[localToken] = [doc_id]\n",
    "#                 elif term_dict[localToken][-1] != doc_id:\n",
    "#                     term_dict[localToken].append(doc_id)\n",
    "# #     break\n",
    "# # print(term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(term_dict, width=1)\n",
    "# print(term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(term_dict['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def removeStopWords(fileName):\n",
    "#     file = open(fileName,'r')\n",
    "#     for line in file:\n",
    "#         if line in termDict:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
