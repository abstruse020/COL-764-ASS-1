{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas- \n",
    "# while saving conpressed postintgs list make\n",
    "# whether to use ?|\\/ for tokenization\n",
    "# iterate over all elements in posting list and save them (will save lots of characters so should reduce writing time)\n",
    "# To save memory - save postings list in next line and while merging only fetch terms and if they match then only get their postings list\n",
    "\n",
    "#implemented\n",
    "# could use bisect insort to insert to list in sorted order (no need now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO-\n",
    "# save docnos to dictionary or index\n",
    "\n",
    "# DONE- \n",
    "#dictionary list (posting lists) are not sorted currently(could do using bisect insort)\n",
    "#merge multiple postings list into 1 (other file)\n",
    "# make query processing (find term from dict file and then dorectly go to position in file) \n",
    "# use porter stemmer for removing words\n",
    "# recheck the ignoring punchuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import porterStemmerModule as psm\n",
    "import snappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionPath = 'tipster-ap-frac'\n",
    "indexFile = 'IndexFile4'\n",
    "#indexFile = 'MyTestIndex'# Change comment un comment up\n",
    "stopwordFile = ''\n",
    "compressionALgo = '3'\n",
    "xmlTagFile = ''\n",
    "tempDirectory = 'temp/'# Change 2 -> None ###IMPORTANT check / or \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) > 5:\n",
    "    collectionPath = sys.argv[1]\n",
    "    indexFile = sys.argv[2]\n",
    "    stopwordFile = sys.argv[3]\n",
    "    compressionALgo = sys.argv[4]\n",
    "    xmlTagFile = sys.argv[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsList = []\n",
    "if stopwordFile != '':\n",
    "    with open(stopwordFile,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        stopwordsList = [line.strip() for line in lines]\n",
    "xmlTagsList = ['DOCNO','HEAD', 'TEXT']\n",
    "if xmlTagFile != '':\n",
    "    with open(xmlTagFile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        xmlTagsList = [line.strip() for line in lines[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOCNO', 'HEAD', 'TEXT']\n"
     ]
    }
   ],
   "source": [
    "print(xmlTagsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"tipster-ap-frac/ap880212\",'r')\n",
    "# ap890520\n",
    "def getFileContents(fileName):\n",
    "    contents = []\n",
    "    with open(fileName,'r') as file:\n",
    "        contents = file.read()\n",
    "    contents = \"<start>\" + contents + \"</start>\"\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTermDictPart(xmlContents,docnos,term_dict = {}, xmlTagsList = ['DOCNO','HEAD', 'TEXT']):\n",
    "    global stopwordsList\n",
    "    ps = psm.PorterStemmer()\n",
    "    docs = xmlContents.find_all('DOC')\n",
    "    tokens = []\n",
    "    for doc in docs:\n",
    "        doc_id = doc.find_all('DOCNO')[0].get_text()\n",
    "        docnos.append(doc_id)\n",
    "        doc_id = len(docnos)\n",
    "        #print(doc_id)\n",
    "        for tag in xmlTagsList[1:]:\n",
    "            tag_all = doc.find_all(tag)\n",
    "            for t in tag_all:\n",
    "                for localToken in filter(None, re.split(\"[ ,.:;\\\"'\\n()\\[\\]{}`]+\",t.get_text())):\n",
    "                    stemmedToken = localToken.strip()\n",
    "                    if not stemmedToken or stemmedToken in stopwordsList:\n",
    "                        continue\n",
    "                    stemmedToken = ps.stem(stemmedToken, 0, len(stemmedToken)-1)\n",
    "                    stemmedToken = stemmedToken.lower()\n",
    "                    #tokens.append([localToken,doc_id])\n",
    "                    #print(localToken, end=\" \");\n",
    "                    #print(\"Token: \",stemmedToken)\n",
    "                    if stemmedToken not in term_dict:\n",
    "                        #print(\"Token: \", stemmedToken)\n",
    "                        term_dict[stemmedToken] = [doc_id]\n",
    "                    elif term_dict[stemmedToken][-1] != doc_id:\n",
    "                        term_dict[stemmedToken].append(doc_id)\n",
    "    return term_dict,docnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTermDict(term_dict, fileName):\n",
    "    a = datetime.datetime.now()\n",
    "    with open(tempDirectory + fileName, 'w') as file:\n",
    "        for key in sorted(term_dict):\n",
    "            file.write('%s %s\\n'%(key, sorted(term_dict[key])))\n",
    "    b = datetime.datetime.now()\n",
    "    #print('save success time taken ='+ str(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Divided Index temp files\n"
     ]
    }
   ],
   "source": [
    "# save term dict for set number of files together in a file\n",
    "saveToFileAt = 10 # Chnage 1 to 10\n",
    "fileNameIndex = 1\n",
    "docnos = []\n",
    "def makeDividedIndex(collectionPath, onlyFiles=False):\n",
    "    print('Making Divided Index temp files')\n",
    "    global fileNameIndex\n",
    "    global docnos\n",
    "    global xmlTagsList\n",
    "    i=1\n",
    "    docnos=[]\n",
    "    term_dict = {}\n",
    "    iterate = collectionPath\n",
    "    if not onlyFiles:\n",
    "        iterate = glob.glob(os.path.join(collectionPath, \"*\"))\n",
    "    \n",
    "    for fileName in iterate:\n",
    "        #print(i,end=\" \")\n",
    "        contents = getFileContents(fileName)\n",
    "        contents = BeautifulSoup(contents, 'xml')\n",
    "        term_dict,docnos = generateTermDictPart(contents,docnos,term_dict, xmlTagsList)\n",
    "        #print(len(docnos))\n",
    "        #print(\"fileName\", end=\" \")\n",
    "        if i % saveToFileAt == 0:\n",
    "            saveTermDict(term_dict, \"TempTermDoc-\"+str(fileNameIndex))\n",
    "            fileNameIndex = fileNameIndex + 1\n",
    "            term_dict = {}\n",
    "        i = i+1\n",
    "    #save if term_dict is not empty (not a multiple of saveToFileAt)\n",
    "    if bool(term_dict):\n",
    "        saveTermDict(term_dict,\"TempTermDoc-\"+str(fileNameIndex))\n",
    "        fileNameIndex = fileNameIndex + 1\n",
    "    #now merge the posting list to a single file\n",
    "\n",
    "makeDividedIndex(collectionPath) # Change uncomment and comment lower\n",
    "#makeDividedIndex(['test', 'test2'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file should be alrea by opened\n",
    "def nextTerm(file):\n",
    "    term = ''\n",
    "    endFile = False\n",
    "    postingList = []\n",
    "    line = file.readline()\n",
    "    if not line:\n",
    "        return term, postingList, True\n",
    "    #line = line[:-1].strip('][').split(', ')\n",
    "    line = list(filter(None, re.split(\"[ ,\\[\\]]+\",line)))\n",
    "    term = line[0]\n",
    "    postingList = [int(x) for x in line[1:-1]]\n",
    "    #postingList = [int(x) for x in line[1:]]\n",
    "    return term, postingList, endFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it efficient (o(n)) currently(o(nlog n))\n",
    "def mergeLists(lists):\n",
    "    lists = [i for li in lists for i in li]\n",
    "    return sorted(lists)\n",
    "#     infi = 100000000000\n",
    "#     lists_itr = [[i[0],0] for i in lists]\n",
    "#     mergedList = []\n",
    "#     lenList = sum(len(x) for x in lists)\n",
    "#     itr = 0\n",
    "#     while True:\n",
    "#         minElement, minIndex = lists_itr[0][0], 0\n",
    "#         for el, i in zip(lists_itr, range(len(lists_itr))):\n",
    "#             if minElement > el[0]:\n",
    "#                 minElement = el[0]\n",
    "#                 minIndex = i\n",
    "#         mergedList.append(minElement)\n",
    "#         itr += 1\n",
    "#         if itr >= lenList:\n",
    "#             break\n",
    "#         if len(lists[minIndex])<= lists_itr[minIndex][1]+1:\n",
    "#             lists_itr[minIndex] = [infi, 0]\n",
    "#         else:\n",
    "#             lists_itr[minIndex] = [lists[minIndex][lists_itr[minIndex][1]+1], lists_itr[minIndex][1] + 1]\n",
    "#     return mergedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergeLists([[3], [2, 4, 5, 7, 10], [7, 9, 15, 71]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li_itr = [[i[0],0] for i in li]\n",
    "# print(li_itr)\n",
    "# print(li_itr[0][0])\n",
    "# n = sum(len(x) for x in li)\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePList(term, plist):\n",
    "    global indexFile\n",
    "    with open(indexFile + '.idx', 'ab') as file:\n",
    "        file.write(bytearray(plist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePlistNoCompression(term , plist):\n",
    "    global indexFile\n",
    "    with open(indexFile + '.idx', 'ab') as file:\n",
    "        file.write(bytearray(plist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "# with open('this.idx', 'rb') as f:\n",
    "#     f.seek(0)\n",
    "#     lst = f.read(n)\n",
    "#     print(lst)\n",
    "#     print(bytearray(lst))\n",
    "#     lst = bytearray(lst).decode()\n",
    "# for i in lst:\n",
    "#     print(i)\n",
    "# print(list(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDict(term, postingListAt):\n",
    "    global indexFile\n",
    "    with open(indexFile + '.dict', 'a') as file:\n",
    "        file.write('%s %s\\n'%(term, postingListAt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitstring_to_bytes(s):\n",
    "    return int(s, 2).to_bytes((len(s) + 7) // 8, byteorder='big')\n",
    "def bytes_to_bitstrings(li):\n",
    "    ans = ''\n",
    "    for i in [bin(i)[2:] for i in li]:\n",
    "        if len(i)%8 != 0:\n",
    "            ans = ans + '0'*(8  - len(i)%8)\n",
    "        ans = ans + i\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gapEncoding(postingList):\n",
    "    if len(postingList) == 0:\n",
    "        #print(\"posting List is empty for gap Encoding\")\n",
    "        return []\n",
    "    encodedList = [postingList[0]]*len(postingList)\n",
    "    for i in range(1,len(postingList)):\n",
    "        encodedList[i] = postingList[i] - postingList[i-1]\n",
    "    return encodedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gapDecoding(postingListEncoded):\n",
    "    for i in range(1, len(postingListEncoded)):\n",
    "        postingListEncoded[i] = postingListEncoded[i] + postingListEncoded[i-1]\n",
    "    return postingListEncoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressC1(postingList):\n",
    "    #print(\"compressing C1\")\n",
    "    finalAns = []\n",
    "    postingList = gapEncoding(postingList)\n",
    "    for item in postingList:\n",
    "        item_byte_array = []\n",
    "        ans = ''\n",
    "        binItem = bin(item)\n",
    "        n = len(binItem)\n",
    "        #print('item\\'s binary: ',binItem)\n",
    "        for i in range(n-1,1, -1):\n",
    "            ans = binItem[i] + ans\n",
    "            if ((n-i) % 7) == 0:\n",
    "                ans = '1' + ans\n",
    "        if (len(ans)%8) != 0:\n",
    "            ans = \"0\"*(8 - (len(ans)%8)-1) + ans\n",
    "            ans = '1' + ans\n",
    "        ans = list(ans)\n",
    "        ans[-8] = '0'\n",
    "        ans = \"\".join(ans)\n",
    "        #print(\"encoded binary\", ans)\n",
    "        for i in range(int(len(ans)/8)):\n",
    "            start = i*8\n",
    "            end = i*8 + 8\n",
    "            #print('\\tto int',ans[start:end], int(ans[start:end],2))\n",
    "            item_byte_array.append(int(ans[start:end],2))\n",
    "        #print('byte array for item: ', item_byte_array)\n",
    "        #ans = int(ans,2)\n",
    "        finalAns = finalAns + item_byte_array\n",
    "        #print('in byte list:',finalAns)\n",
    "    return finalAns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compressC1([8019, 24711, 27689, 42921, 43210, 43402, 44079, 49625, 50737, 54429, 57261, 80205, 83298, 86796, 106040, 120846, 131611, 136697, 151642, 155925, 156058, 156103, 156104, 156291, 157516, 157627])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking int list for compression and Returning boolean string after compression (need to convert to list of bytes)\n",
    "#Taking bool string before decompression and Returning int list after compression (need to convrt list of bytes to bool str)\n",
    "### IMPORTANT ----- ITS ENCODING 0 AND 1 AS 0 (SO DON'T USE 0 FOR DENOTING DOCUMENT ID OR USE +1 AND -1 FOR ALL)\n",
    "\n",
    "class compressionC2:\n",
    "    def __init__(self):\n",
    "        self.postingList = ''\n",
    "        self.compressedList = ''\n",
    "    def l(self,x):\n",
    "        return len(bin(x)[2:])\n",
    "    def lsb(self,x):\n",
    "        return bin(x)[3:]\n",
    "    def u(self, x):\n",
    "        return '1'*(x - 1) + '0'\n",
    "    def compressItem(self, item):\n",
    "        lx = self.l(item)\n",
    "        llx = self.l(lx)\n",
    "        return self.u(llx) + self.lsb(lx) + self.lsb(item)\n",
    "    def compress(self, postingsList):\n",
    "        postingsList = gapEncoding(postingsList)\n",
    "        postingsList = [ i+2 for i in postingsList]\n",
    "        compressedList = ''\n",
    "        for item in postingsList:\n",
    "            compressedList = compressedList + self.compressItem(item)\n",
    "        return compressedList\n",
    "    def decompressItem(self, compressedList):\n",
    "        index = 0\n",
    "        llx = 0\n",
    "        lx = ''\n",
    "        while compressedList[index] == '1':\n",
    "            llx += 1\n",
    "            index +=1\n",
    "        llx+=1\n",
    "        index+=1\n",
    "        #print('llx:', llx, 'index: ', index)\n",
    "        lx = int('1' + compressedList[index : index + llx - 1],2)\n",
    "        #print('lx:', lx)\n",
    "        index = index + llx - 1\n",
    "        #print(compressedList[index: index + lx -1])\n",
    "        x = int('1' + compressedList[index : index + lx - 1],2)\n",
    "        #print('x',x)\n",
    "        return x, index + lx -1\n",
    "    def decompress(self, compressedList):\n",
    "        postingsList = []\n",
    "        index = 0\n",
    "        while index < len(compressedList) and compressedList[index] == '0':\n",
    "            index+=1\n",
    "        while index < len(compressedList):\n",
    "            item, bitsProcessed = self.decompressItem(compressedList[index : ])\n",
    "            index += bitsProcessed\n",
    "            postingsList.append(item)\n",
    "        postingsList = [ i-2 for i in postingsList]\n",
    "        postingsList = gapDecoding(postingsList)\n",
    "        return postingsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressC3(postingsList):\n",
    "    if len(postingsList) == 0:\n",
    "        return None\n",
    "    postingsList = gapEncoding(postingsList)\n",
    "    string = ''\n",
    "    for el in postingsList:\n",
    "        string += str(el) + ','\n",
    "    return snappy.compress(string[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressPList(postingsList, algo):\n",
    "    if algo == '0':\n",
    "        return str(postingsList).encode()\n",
    "    if algo == '1':\n",
    "        return compressC1(postingsList)\n",
    "    elif algo == '2':\n",
    "        c2 = compressionC2()\n",
    "        compList = c2.compress(postingsList)\n",
    "        return bitstring_to_bytes(compList)\n",
    "    elif algo == '3':\n",
    "        return compressC3(postingsList)\n",
    "    elif algo == '4':\n",
    "        return None\n",
    "    elif algo == '5':\n",
    "        return None\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveEssentialsDict(stopwordsList =[], docnos=[], compressionALgo='0'):\n",
    "    global indexFile\n",
    "    if os.path.exists(indexFile+ '.dict'):\n",
    "        os.remove(indexFile + '.dict')\n",
    "    with open(indexFile+'.dict', 'a') as f:\n",
    "        f.write('%s\\n'%(stopwordsList))\n",
    "        f.write('%s\\n'%(docnos))\n",
    "        f.write('%s\\n'%(compressionALgo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge time: 0:00:05.003057\n",
      "save Time: 0:01:15.353521\n",
      "compressionTime: 0:00:39.026950\n",
      "Time :0:04:09.874291\n"
     ]
    }
   ],
   "source": [
    "######################################## start from here\n",
    "# could remove eofs and use terms = '' for breaking the loop -- leave it\n",
    "import datetime\n",
    "FilesWithList = fileNameIndex - 1\n",
    "saveEssentialsDict(stopwordsList, docnos, compressionALgo)\n",
    "def makeIndexAndDict(compressionAlgo):\n",
    "    if os.path.exists(indexFile+ '.idx'):\n",
    "        os.remove(indexFile + '.idx')\n",
    "    terms = ['']*FilesWithList\n",
    "    postingsLists = [[]]*FilesWithList\n",
    "    # Path\n",
    "    files = [ open(tempDirectory + 'TempTermDoc-'+ str(i+1)) for i in range(FilesWithList)]\n",
    "    eofs = [False] * FilesWithList\n",
    "    #initial initialisation of terms and posting list\n",
    "    for i in range(FilesWithList):\n",
    "        terms[i], postingsLists[i], eofs[i] = nextTerm(files[i])\n",
    "    a = datetime.datetime.now()\n",
    "    postingsListPointer = 0\n",
    "    terms_in_dict = 0\n",
    "    mergeTime =  a- a\n",
    "    savingTime = a - a\n",
    "    compressionTime = a - a\n",
    "    while True:\n",
    "        terms_in_dict += 1\n",
    "        #print(terms_in_dict, end=\" \")\n",
    "        # find min in terms except '' (if eof is reached those terms are = ''(empty string))\n",
    "        minTerm = min([term for term in terms if term != ''])\n",
    "        minTermsIndex = []\n",
    "        for term, index in zip(terms, range(len(terms))):\n",
    "            if term == minTerm:\n",
    "                minTermsIndex.append(index)\n",
    "                \n",
    "        #merge Postings Lists for same terms (min terms among all)\n",
    "        t1 = datetime.datetime.now()\n",
    "        minTermPList = mergeLists([postingsLists[i] for i in minTermsIndex])\n",
    "        t2 = datetime.datetime.now()\n",
    "        mergeTime = mergeTime + t2 - t1\n",
    "        #print('merger :',t2-t1)\n",
    "        #print('term', minTerm)\n",
    "        #print('plist orig', minTermPList)\n",
    "        #compress the posting lsit (got list of bytes)\n",
    "        minTermPList = compressPList(minTermPList, compressionAlgo)\n",
    "        #print(\"PList\", minTermPList)\n",
    "        compressionTime += datetime.datetime.now() - t2\n",
    "        \n",
    "        #save Postings Lists\n",
    "        t3 = datetime.datetime.now()\n",
    "        if compressionAlgo !='0':\n",
    "            savePList(minTerm, minTermPList)\n",
    "        else:\n",
    "            savePlistNoCompression(minTerm, minTermPList)\n",
    "        savingTime += datetime.datetime.now() - t3\n",
    "        \n",
    "        #save dictionary\n",
    "        #print(postingsListPointer)\n",
    "        saveDict(minTerm, postingsListPointer)\n",
    "        #update plist pointer for dictionary\n",
    "        postingsListPointer += len(minTermPList)\n",
    "        \n",
    "        #t3 = datetime.datetime.now()\n",
    "        #print('save :', t3 - t2)\n",
    "        #iterate to next terms\n",
    "        for index in minTermsIndex:\n",
    "            terms[index], postingsLists[index], eofs[index] = nextTerm(files[index])\n",
    "        #if all eofs reached end the loop\n",
    "        if all(eofs):\n",
    "            break\n",
    "    \n",
    "    for f in files:\n",
    "        f.close()\n",
    "    b = datetime.datetime.now()\n",
    "    print('merge time:',mergeTime)\n",
    "    print('save Time:', savingTime)\n",
    "    print('compressionTime:', compressionTime)\n",
    "    print('Time :'+ str(b - a))\n",
    "    #print(terms)\n",
    "    #print(postingsLists)\n",
    "makeIndexAndDict(compressionALgo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def makeCompressedIndexDict(compressionAlgo):\n",
    "#     global indexFile\n",
    "#     if os.path.exists(indexFile + '.dict'):\n",
    "#         os.remove(indexFile + '.dict')\n",
    "#     if os.path.exists(indexFile+ '.idx'):\n",
    "#         os.remove(indexFile + '.idx')\n",
    "#     t1 = datetime.datetime.now()\n",
    "#     term = ''\n",
    "#     postingsList = []\n",
    "#     postingsListPointer = 0\n",
    "#     with open('PostingsListNoCompression', 'r') as file: # Change 2' -> '\n",
    "#         while True:\n",
    "#             line = file.readline()\n",
    "#             if not line:\n",
    "#                 break\n",
    "#             line = list(filter(None, re.split(\"[ ,\\[\\]]+\",line)))\n",
    "#             term = line[0]\n",
    "#             postingsList = [int(x) for x in line[1:-1]]\n",
    "#             postingsList = compressPList(postingsList, compressionAlgo)\n",
    "#             savePList(term, postingsList)\n",
    "#             saveDict(term, postingsListPointer)\n",
    "#             postingsListPointer += len(postingsList)\n",
    "#     print('time taken to compress postings list: ', datetime.datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to compress postings list:  0:00:00.030328\n",
      "0:00:00.031065\n"
     ]
    }
   ],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# makeCompressedIndexDict('2')\n",
    "# print(datetime.datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b11000110\n"
     ]
    }
   ],
   "source": [
    "# c2 = compressionC2()\n",
    "# print(bin(198))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000 6\n",
      "b'\\x00'\n"
     ]
    }
   ],
   "source": [
    "# compressed = c2.compress([1,2,3,4,5,6])\n",
    "# print(compressed, len(compressed))\n",
    "# print(bitstring_to_bytes(compressed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-283-828ba64618a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompressed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecompressed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-257-69392f9e880d>\u001b[0m in \u001b[0;36mdecompress\u001b[1;34m(self, compressedList)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mpostingsList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mcompressedList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompressedList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# decompressed = c2.decompress(compressed)\n",
    "# print(decompressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bitstring_to_bytes(s):\n",
    "#     return int(s, 2).to_bytes((len(s) + 7) // 8, byteorder='big')\n",
    "# def bytes_to_bitstrings(li):\n",
    "#     ans = ''\n",
    "#     for i in [bin(i)[2:] for i in li]:\n",
    "#         if len(i)%8 != 0:\n",
    "#             ans = ans + '0'*(8  - len(i)%8)\n",
    "#         ans = ans + i\n",
    "#     return ans \n",
    "# # string = '1000010001000'\n",
    "# # byt = bitstring_to_bytes(string)\n",
    "# # print(byt)\n",
    "# # print(bytes_to_bitstrings(byt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# for i in b'\\x02\\x11':\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# for i in range(100):\n",
    "#     c2 = compressionC2([10]*10000)\n",
    "# print('tiem taken: ',datetime.datetime.now() - t1)\n",
    "# print(len(c2.compress()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressionC2([119]).compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getInt(binaryNum):\n",
    "#     return int(binaryNum, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #assuming its bytestream stream\n",
    "# def decompressC1(plist):\n",
    "#     postingList = []\n",
    "#     #print(len(plist))\n",
    "#     numberOfBytes = int(len(plist))\n",
    "#     binaryItem = ''\n",
    "#     docNo = 0\n",
    "#     toAddNumber = 0\n",
    "#     for byt in plist:\n",
    "#         #print('for',byt)\n",
    "#         if byt < 128:\n",
    "#             docNo = docNo*128 + byt\n",
    "#             postingList.append(docNo)\n",
    "#             toAddNumber = 0\n",
    "#             docNo = 0\n",
    "#         else:\n",
    "#             byt -= 128\n",
    "#             docNo = docNo*128 + byt\n",
    "#             toAddNumber += 1\n",
    "#     postingList = gapDecoding(postingList)\n",
    "#     return postingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 + 64 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = compressC1([8019,2137991])\n",
    "# print(comp)\n",
    "# print(decompressC1(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing binary file\n",
    "# with open('testb','wb')as file:\n",
    "#     s = 'm101'\n",
    "# #     x = b'0101'\n",
    "#     x = bytes(s,'ascii')\n",
    "#     print(x)\n",
    "#     file.write(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('testb','rb') as file:\n",
    "#     x = file.read(1)\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('testb', 'wb') as file:\n",
    "#     byte_arr = [1,2,3,4, 255]\n",
    "#     byte_arr = bytearray(byte_arr)\n",
    "#     file.write(byte_arr)\n",
    "#     print(byte_arr, len(byte_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('testb', 'rb') as file:\n",
    "#     file.seek(2)\n",
    "#     byte_arr = file.read(2)\n",
    "#     print(byte_arr)\n",
    "#     print(len(byte_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_string = '00000011'\n",
    "# byt = int(bin_string, 2)\n",
    "# print(byt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def removeStopWords(fileName):\n",
    "#     file = open(fileName,'r')\n",
    "#     for line in file:\n",
    "#         if line in termDict:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
